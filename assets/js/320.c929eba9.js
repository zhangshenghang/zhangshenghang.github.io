(window.webpackJsonp=window.webpackJsonp||[]).push([[320],{686:function(a,n,t){"use strict";t.r(n);var r=t(8),s=Object(r.a)({},(function(){var a=this,n=a._self._c;return n("ContentSlotsDistributor",{attrs:{"slot-key":a.$parent.slotKey}},[n("h1",{attrs:{id:"sparkstreaming参数介绍"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#sparkstreaming参数介绍"}},[a._v("#")]),a._v(" SparkStreaming参数介绍")]),a._v(" "),n("ul",[n("li",[a._v("spark.streaming.concurrentJobs :增加job并行度")])]),a._v(" "),n("div",{staticClass:"language- line-numbers-mode"},[n("pre",{pre:!0,attrs:{class:"language-text"}},[n("code",[a._v('可以通过集中方法为streaming job配置此参数。 \n- spark-default中修改 \n全局性修改，所有的streaming job都会受到影响。 \n- 提交streaming job是 –conf 参数添加（推荐） \n在提交job时，可以使用–conf 参数为该job添加个性化的配置。例如： \nbin/spark-submit --master yarn --conf spark.streaming.concurrentJobs=5 \n设置该streaming job的job executor 线程池大小为5，在资源充足的情况下可以同时执行5个batch job。 \n- 代码设置 \n在代码中通过sparkConf设置： \nsparkConf.set("spark.streaming.concurrentJobs", "5"); \n或者 \nSystem.setProperty("spark.streaming.concurrentJobs", "5");\n')])]),a._v(" "),n("div",{staticClass:"line-numbers-wrapper"},[n("span",{staticClass:"line-number"},[a._v("1")]),n("br"),n("span",{staticClass:"line-number"},[a._v("2")]),n("br"),n("span",{staticClass:"line-number"},[a._v("3")]),n("br"),n("span",{staticClass:"line-number"},[a._v("4")]),n("br"),n("span",{staticClass:"line-number"},[a._v("5")]),n("br"),n("span",{staticClass:"line-number"},[a._v("6")]),n("br"),n("span",{staticClass:"line-number"},[a._v("7")]),n("br"),n("span",{staticClass:"line-number"},[a._v("8")]),n("br"),n("span",{staticClass:"line-number"},[a._v("9")]),n("br"),n("span",{staticClass:"line-number"},[a._v("10")]),n("br"),n("span",{staticClass:"line-number"},[a._v("11")]),n("br"),n("span",{staticClass:"line-number"},[a._v("12")]),n("br")])]),n("ul",[n("li",[a._v("spark.streaming.kafka.maxRatePerPartition:每秒每一个topic的每一个分区获取的最大消息数。")])]),a._v(" "),n("blockquote",[n("p",[a._v("合理的批处理时间（batchDuration）"),n("br"),a._v("\n几乎所有的Spark Streaming调优文档都会提及批处理时间的调整，在StreamingContext初始化的时候，有一个参数便是批处理时间的设定。\n如果这个值设置的过短，即个batchDuration所产生的Job并不能在这期间完成处理，那么就会造成数据不断堆积，最终导致Spark Streaming发生阻塞。\n一般对于batchDuration的设置不会小于500ms，因为过小会导致SparkStreaming频繁的提交作业，对整个streaming造成额外的负担。\n在平时的应用中，根据不同的应用场景和硬件配置，我设在1~10s之间，我们可以根据SparkStreaming的可视化监控界面，观察Total Delay来进行batchDuration的调整，直达SparkStreaming刚刚能及时处理完上一个批处理的数据，这样就是目前情况的最优值。")])]),a._v(" "),n("blockquote",[n("p",[a._v("合理的Kafka拉取量（maxRatePerPartition重要）\nspark.streaming.kafka.maxRatePerPartition参数配置指定了每秒每一个topic的每一个分区获取的最大消息数。"),n("br"),a._v("\n对于Spark Streaming消费kafka中数据的应用场景，这个配置是非常关键的。这个参数默认是没有上限的，即kafka当中有多少数据它就会直接全部拉出。而根据生产者写入Kafka的速率以及消费者本身处理数据的速度，同时这个参数需要结合上面的batchDuration，使得每个partition拉取在每个batchDuration期间拉取的数据能够顺利的处理完毕，做到尽可能高的吞吐量，而这个参数的调整可以参考可视化监控界面中的Input Rate和Processing Time")])]),a._v(" "),n("ul",[n("li")])])}),[],!1,null,null,null);n.default=s.exports}}]);